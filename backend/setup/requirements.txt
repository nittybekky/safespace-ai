transformers==4.38.1
torch==2.2.0
fastapi==0.109.2
uvicorn==0.27.1
pydantic==2.6.1
ctranslate2==3.24.0           # For GGUF optimization
pylru-cache==1.1.0            # For caching
loguru==0.7.2                 # For better logging
safetensors==0.4.1           # For model loading